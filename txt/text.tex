\documentclass[a4paper,11pt,twoside]{ltxdoc}

%\usepackage[utf8]{inputenc} % not used, as I compile with Xelatex
\usepackage[T1]{fontenc}
\usepackage[english]{babel} % Language, could be set to swedish
\usepackage{fancyhdr} % Header and footers
\usepackage{verbatim} % Better Verbatim packages
\usepackage{fancyvrb}
\usepackage{amssymb,amsmath}
\usepackage{graphicx} % PNG and SVG images, and such.
\usepackage{enumerate} % better listing options
\usepackage{hyperref} % URL and stuff.

\pagestyle{fancy}

\fancyhead[LH]{Group 11}
\fancyhead[RH]{Sentiment Analysis in Speech with Relation to Brands}
%\fancyfoot[LO]{\thepage}
%\fancyfoot[RE]{\thepage}
\title{Project: Search Engines and Information Retrieval Systems}
\author{
Jens Arvidsson <\href{mailto:jensarv@gmail.com}{jensarv@gmail.com}> \and
Fredrick Chahine <\href{mailto:fchahine@kth.se}{fchahine@kth.se}> \and
Erik Hallström  <\href{mailto:erik_hallstrom@icloud.com}{erik\_hallstrom@icloud.com}> \and
Petter Salminen <\href{mailto:petsal@kth.se}{petsal@kth.se}>}


% Kodkommando
\newcommand{\javafil}[1]{\lstinputlisting{#1}} % #1 = filnamn, #2 = caption
\newcommand{\ovning}[1]{\section*{Övning #1}}

\begin{document}
\maketitle
\tableofcontents

%\listoffigures
%\listoftables
\newpage
\begin{abstract}
Text goes here...

\end{abstract}

\newpage
\section{Background}
Technology is ever moving forward.
We're always looking for new ways to interact with your systems and devices. One of these ways to input information to computers would be by natural speech, which still is quite flimsy and hard for computers to analyse. 

With most of our media still being partly or fully in form of sound, such as web-radio, and television. It is hard to analyse all the information being run around on this media, as the format is not native to our computers and systems. 

With this is mind, our mission is to make an experimental program that can transcribe speech and analyse it, looking for certain trends.
For example, this can be used to recognise branding recognition from a audio stream, and then analyse the context to find an opinion about the brand.
A complete solution could be very interesting for companies who care to know how their brand is doing ``out there'' in the world.

To be able to find automatically information in the wast sea of digital audio/video media is a very challenging problem
because the information itself is very hard for computers to read. 



\section{Related Work}
\subsection{Speech-to-Text}
\emph{Speech-to-text}, or more generally \emph{Computer Speech Recognition} is the general problem in computer science where the computer has to translate spoken words into text.

The first real attempt to do speech recognition was made during the 50's and the system could only handle a small subset of speech, namely digit recognition. In 1952 reasearchers at Bell Laboratories built a speech recognition system that only could recognize digits by a single speaker in a quiet room. The thechnology of  the system was based on the theory of the acoustics of speech and the machine triggered on the sound of the vovels in the different digits.

Similar work was made by researchers at RCA Laboratories and at MIT Lincoln Lab during the 50's. The research teams at these two institutions built speech recognitions systems that could classify vovels that a test person spoke.

Moving on to the 60's, there were severeal Japanese teams that had progress with speech recognition, especially two professors named Suzuki and Nakata at Kyoto University. Even though they still only could recognize single digits or vovels, however the difference here was that these could be recognized in countinous speech. The earlier systems assumed each utterance of the test speaker contained the complete digit or vovel and thus did not need to be actively segmented.  

During the 70's the first speech recognition system that could handle spoken words an sentences began to be developed. A program named "Harpy" was made at Carnegie Mellon University and could recognize speech containing 1011 different words. It had a moderate preformance . Harpy used a graph search algorithm to obtain the results. 

A new technology based on the n-gram language model, was introduced in the beginning of the 80's and have been very important to speech recognition systems ever since. One obvious task for a speech recognizer is to use it as a automatic typewriter; a user speaks words and sentences that should be written to a document. Since there is an underlying structure and grammar in all form of language, not all letter orderings and word orderings are equally probable. In fact, some orderings are even wrong, i.e the words are misspelled or sentences are gramatically incorrect. The n-gram model looks at a sequence of words and tells how probable it is. That will help when doing the word recognition, we will get a prior for each word and thus use a M.A.P estimation for what the next word ought to be.

These typewriters was suppose to be used extensively by certain persons, it thus allowed for individual training of the system. This was not the case for another application of speech recognition, namely routing phonecalls

Today the use of Speech-to-Text can be found in many different fields and applications.

As an example, court reporting where everything said in court could be recorded and automatically transcribed by a computer (replacing human labour).
Hands-free computing, meaning one could write messages and emails by just talking to the computer.
Automatic calling exchanges at service numbers,
such that one could ask the problem and get directed to a expert within the specific field.

Or on current generation of cellphones as popularised by the Apple iPhone's application Siri
- supplying an intelligent personal assistant and knowledge navigator that you can ask questions in natural language and get an answer. 



\subsection{Text attitude}
This is quite as it sounds like. Given any text snippet,
the problem is to analyse and find the general attitude of given text.
For example the text ``I hate Mondays'' has a very negative attitude,
while the attitude of ``I would not prefer Mondays'' is more towards neutral.

To be able to get the general opinion or attitude from a text can be very useful for companies that care about their reputation.
Thus for example finding a lot of complains about something could give great automatic feedback.


\section{Method}
Our solution for this problem consists of not trying to invent the wheel, but trying to use different
more-or-less complete solutions for the different steps and stitch then together into our own framework.

First and foremost we have an audio file, which we will send to Google speech API, which will give us a fair caption of the given sound segment.

This text we can then search for given brands or other point of interests, and then send this text for textual attitude analysing using an web API provided by our mentor at Gavagai.

From here we will get an score, of which we can show the user what kind of attitude the speech had. 

\section{Results}


\section{Discussion}


\newpage 

%% Here is the ref system, where you add an item
%% as you can see with the \bibitem{NAME} field.
%%
%% To in the text refer to a certain reference, use
%% this command \cite{NAME}
%%
\begin{thebibliography}{9}

\bibitem{example}
  Leslie Lamport,
  \emph{\LaTeX: A Document Preparation System}.
  Addison Wesley, Massachusetts,
  2nd Edition,
  1994.

\bibitem{example2}
  Leslie Lamport,
  \emph{\LaTeX: A Document Preparation System}.
  Addison Wesley, Massachusetts,
  2nd Edition,
  1994.


\end{thebibliography}

\end{document}
